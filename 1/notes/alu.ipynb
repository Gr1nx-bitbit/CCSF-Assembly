{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1bit half-adder** (HA): made up of XOR and AND logic gates. Two of these together can make a **full-adder** (FA) which can also be made out of logic gates. HAs take in two bits A and B and produce two bits S and C where S is the sum and C is the carry bit. A full adder takes in two bits A and B as well as a Carry-in bit CI to produce two bits, the sum S and the Carry-out bit CO. \n",
    "\n",
    "While ANDs are like && from programming and ORs are || from programming, **multiplexers** are the if from programing. Multiplexers take in two bits A and B and a Selector / Control bit S and produces the A or B bit based on what S is; I'm guessing S is like the expression output of 3 == 4 or something, like this will produce 0 since its false? Idk.\n",
    "\n",
    "A 1bit ALU would be made of an FA, an AND gate, an OR gate, and a multiplexer. The FA does arithmetic while the AND and OR do logic and the multiplexer switches between logic and arithmetic work. If arithmetic is to be performed, the multiplexer takes in the 3 bits and spits out the sum along with the CO bit while only spitting out the value for an AND or OR operation without the CO bit. \n",
    "\n",
    "The **zero-bit** signifies whether two values A and B are equal. If it's 0, then the values are NOT equal, otherwise, they are. The zero-bit is a type of **flag**, which is a bit to represent some value, situation, or circumstance. \n",
    "\n",
    "Remember, that to perform binary subtraction using 2's compliment, we take each bit in a sequence and switch it to its compliment, then after all the bits have been switched, we add 1 to the entire sequence. If we then add a NOT gate to the ALU, we can negatize a sequence of bits using the NOT gate and then add that negative bit sequence to a positive or negative to simulate subtraction. \n",
    "\n",
    "Some ways of detecting overflow in the ALU is by checking whether the sign of your number has changed after you've added same signed inputs i.e. if you add 4 and 3 and get -2, something is wrong; I imagine this happens because that first bit to represent the sign gets carried into and becomes its compliment making the number negative. Yup, that's right. \n",
    "\n",
    "Since we're working with bits, we can't just directly represent < or > signs. To derive these signs, we can use the zero-bit and subtraction to see if the sign of a value has changed after an operation. If A - B shows a change in sign, we know A < B and therefore we can assign the \"less than\" flag a bit of either 0 or 1. We can probably do the same thing for \"greater than\" but just swap the values. \n",
    "\n",
    "Handling overflow basically consists of checking if the sign has been changed or is wrong, storing that value in a flag and checking it and then changing the sign back to what it should be. Knowing this, we can make digital logic to check for overflow. One bit will represent the overflow state, another, the sume of two bits, and the third, whether the first or second bit is bigger (check module 1.54 for the truth table). This table matches a XORs truth table so we could just use that instead to check for overflow. For the XOR gate, we would use the overflow and sum bits as inputs spitting out whether A or B is bigger as an ouput. Check out module 1.55 for the 1bit ALU design. \n",
    "\n",
    "<h3>Carry Look Ahead Addition</h3>\n",
    "Idek why we need to know this to be honest. When doing addition the beta way, one adder feeds into another and so on, but all sequential adders have to wait for the previous to finish adding a propogation delay which is no good if you want to be fast. Uh, ok. Basically, you can make your digital logic more complex so that additions finish at the same time instead of one after another. You can modify the more complex designs to fit different bit-sized architectures such as 4bit, 16bit, or 32bit. I didn't really understand any of what happened, especially the digital logic diagrams they showed but hey, maybe I'll get there. \n",
    "\n",
    "For addition of Nbit numbers, you can cascade N adders to be able to do so. But there is propogation delay to this approach because of its sequential nature. The moral of the story is that you can take a sequence of adders to compute an N bit number. \n",
    "\n",
    "Aha. This carry bit is what it sounds like. When we add bits together, a XOR gate works just fine until we get to 1 + 1. 0 + 0 = 0, 0 + 1 = 1, 1 + 0 = 1, but 1 + 1 â‰  0, instead it equals *10*. Remember that the bit is **carried** over, so we need a bit column to represent that carrying over, giving us A and B as input with the Sum    (2^0's place) and a carry bit as output. We add an AND gate to get that carry bit in there. This XOR and AND gate create the HA. An FA is used when we want to compute three bits such as 1 + 1 + 1. We do this by feeding the sum from the first half adder into a second half adder, the third bit C into the second half adder, then feeding the carry bits of both HAs into an OR gate and the sum of the second HA somewhere else (the output?). An FA takes in THREE inputs while an HA only takes in TWO. The reason the full adder takes in 3 inputs is to deal with a **carryover bit**. So if we have a case of 1 + 1 with the half adder, a carry bit is fed into the full adder along with the other two input bits.\n",
    "\n",
    "As we chained HAs together, we can now chain 1 HA into a FA and then FA into subsequent ones following the paradigm before. One ripples into the other which can takes a while and is where we get the propogation delay from. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
